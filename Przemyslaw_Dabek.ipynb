# Odpalamy biblioteki do mojej ( mam nadzieje :) przyszlej regresj
import numpy as np # tutaj do mojej ( mam nadzieje :) przysz lej regresj
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
import pandas as pd # do otwierania i ogolnie pracy na zbiorze
import matplotlib.pyplot as plt # tutaj plus seabron do wykresow
import seaborn as sns
from matplotlib.colors import ListedColormap
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_percentage_error
from sklearn.linear_model import Lasso,Ridge,ElasticNet
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, PolynomialFeatures,StandardScaler,RobustScaler

# Tutaj odpalam plik 
df = pd.read_csv(r'C:\Users\pkoni\Desktop\train.csv')
target = df['SalePrice']
#Tutaj sprawdzam rodzaj danych
df.info()
# Tutaj wyciągam sobie miary dla naszego target value średnia itp.
target.describe()

# Tutaj tworze test/train datasety pod przyszła regresje oraz zamieniamy dane na binearne ( słowa na liczby z funkcji dummies)
df=  pd.get_dummies(df)
df

#Tutaj patrze dla siebie jak wygląd relacja wiek vesrus cena 
x1 = target
y1 = df['Year.Built']
plt.figure(figsize=(16,9))
plt.scatter(x1,y1,   c ="blue")
plt.show()

#Tutaj sprawdzam typ danych, ile jest numerycznych 
typ_danych=[]
for col in df.columns:
    nulltest = df[col].dtype
    if df[col].dtype in ['int64','float64']:
        typ_danych.append('numeryczne')
    else:
        typ_danych.append('slowne')
plt.figure(figsize=(16,9))
sns.countplot(x=typ_danych)
plt.show()

#Tutaj sprawdzam ile jest braków w danych liczbowych 
check_num = df.columns[df.dtypes != 'object']
check_num.isnull().sum()

# sprawdzam tutaj za pomocą isnull z biblioteki pandas co gdzie i ile mamy nulli oraz sortuje je nie rosnąco 
tot = df.isnull().sum().sort_values(ascending=False)
procent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)
# tutaj stworzylem mały data frame z liczba nulli i ich % uddziałem pod wykres 
total = pd.DataFrame({
    'liczba': tot,
    'procent': procent
})
braki = list(df.to_dict().keys())
total.head(10)

# Tutaj wrzucam missing value na wykres, aby lepiej sobie to zobrazować
wykres1 = total[total['liczba']>0]
plt.figure(figsize=(16, 9))
sns.barplot(y=wykres1.head(11).index,
            x=wykres1.head(11).liczba,
            palette='terrain_r')
plt.title("Liczbowy udział missingow")

#Tutaj sprawdzam jakie są najczęsciej występujące słowa (wartości) za pomocą .mode() w missingach
print('Bsmt.Exposure:', df['Bsmt.Exposure'].mode())
print('Mas.Vnr.Type:', df['Mas.Vnr.Type'].mode())
print('BsmtFin.Type.2:', df['BsmtFin.Type.2'].mode())
print('Garage.Finish:', df['Garage.Finish'].mode())
print('Bsmt.Cond:', df['Bsmt.Cond'].mode())
print('Bsmt.Qual:', df['Bsmt.Qual'].mode())
print('BsmtFin.Type.1:', df['BsmtFin.Type.1'].mode())
print('Garage.Cond:', df['Garage.Cond'].mode())
print('Garage.Qual:', df['Garage.Qual'].mode())

#Tutaj uzupełniam missingi najczęsciej występującymi słowami w danej kolumnie
df['Bsmt.Exposure'].fillna('No', inplace=True)
df['BsmtFin.Type.2'].fillna('Unf', inplace=True)
df['Garage.Finish'].fillna('Unf', inplace=True)
df['Bsmt.Cond'].fillna('TA', inplace=True)
df['Bsmt.Qual'].fillna('VinyTAlSd', inplace=True)
df['BsmtFin.Type.1'].fillna('GLQ', inplace=True)
df['Garage.Cond'].fillna('TA', inplace=True)
df['Garage.Qual'].fillna('TA', inplace=True)
df['Mas.Vnr.Type'].fillna('None', inplace=True)

#Tutaj za pomocą metody IQR staram się usunąć outliers
per25 = df['SalePrice'].quantile(0.25)
per75 = df['SalePrice'].quantile(0.75)
iqr = per75 - per25
upper = per75 + 1.5 * iqr
lower = per25 - 1.5 * iqr
df[df['SalePrice'] > upper]
df[df['SalePrice'] < lower]

new_df = df[df['SalePrice'] < upper]
new_df.shape
plt.figure(figsize=(16,8))
sns.distplot(df['SalePrice'])
plt.subplot(2,2,2)
sns.boxplot(df['SalePrice'])
plt.subplot(2,2,4)
sns.boxplot(new_df['SalePrice'])
plt.show()
df = df.copy()
df['SalePrice'] = np.where(
    df['SalePrice'] > upper,
    upper,
    np.where(
        df['SalePrice'] < lower,
        lower,
        df['SalePrice']
    )
)
plt.figure(figsize=(16,8))
plt.subplot(2,2,1)
sns.boxplot(new_df['SalePrice'])
plt.subplot(2,2,3)
sns.boxplot(df['SalePrice'])
plt.show()
# Tutaj przygotowujemy dane do modelu regresji liniowej 
df=  pd.get_dummies(df)
y = df['SalePrice'].values
X= df.drop('SalePrice',axis=1).values
X
X_train, X_test,y_train, y_test= train_test_split(X,y,test_size=0.3,random_state=42)
reg= LinearRegression()
regr = reg.fit(X_train,y_train)
pred = reg.predict(X_test)
# Tutaj przygotowujemy dane do modelu Lasso
X_train ,X_test ,y_train ,y_test = train_test_split(X, y, test_size=0.3, random_state=0) 

moele_Lasso = Lasso(alpha=0.5)
moele_Lasso.fit(X_train, y_train)

y_pred_Lasso = moele_Lasso.predict(X_test)
    
print(
f'MSE：{mean_squared_error(y_test, y_pred_Lasso):.3f}\n'
f'R2：{r2_score(y_test, y_pred_Lasso):.3f}')

# Tutaj przygotowujemy dane do modelu regresji grzbietowej
moele_Ridge = Ridge(alpha=0.5)
moele_Ridge.fit(X_train, y_train)

y_pred_Ridge = moele_Ridge.predict(X_test)
    
print(
          f'MSE：{mean_squared_error(y_test, y_pred_Ridge):.3f}\n'
          f'R2：{r2_score(y_test, y_pred_Ridge):.3f}')